---
title: "00-midterm-inclass"
author: "Charlie Reinhardt"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


“All work presented is my own. I have not communicated with or worked with anyone else on this exam.”

Collaboration Reminder: You may not communicate with or work with anyone else on this exam, but you may use any of our course materials or materials on the Internet.

**Question 1** (20 points). Examine the following plot that uses the `pokemon_full.csv` data set. The plot gives the count of each Pokemon type.

```{r}
library(tidyverse)
library(here)
pokemon_df <- read_csv(here("data/pokemon_full.csv"))
pokemon_type <- pokemon_df %>% group_by(Type) %>% summarise(type_count = n())

ggplot(data = pokemon_type, aes(x = Type, y = type_count)) +
  geom_bar(stat = "identity") +
  labs(x = "Type",
       y = "Count") +
  coord_flip()
```

**part a**. Which of the 7 grammar of graphics parameters are explicitly specified in the code to make the plot?

Data, aesthetic mappings, geom_function, statistical transformation, coordinate system are all explicitly specified. Position adjustment and facet function are NOT explicitly declared.

**part b.** For these types of plots, we have usually reordered the Type so that the type with the most Pokemon would be first and the type with the least number of pokemon would be last. Use a principle from the Data Visualization Reading to explain why we would want to do this.

By switching the order in which Types appear, we encode a comparison order into our graph, making it easier to place the types in order from greatest to least. Putting similar sized bars to be next to eachother makes comparison easier. This is a concept called proximity: it is easier to group things together (high type count or low type count) when they are near eachother.

**part c.** We have also stated that, for bar plots and lollipop plots, 0 should be included in the plot. On the other hand, for point plots and scatterplots, 0 need not be included. Using a principle from the Data Visualization Reading, explain why it is okay to omit 0 from a point plot but not from a bar plot.

when encoding length or size (as bar charts do), viewers inherently compare how much ink they see and compare relative sizes of bars. If a graph omits 0, a count of 75 could seem 25 times as large as a count of 50 in a bar chart, which is misleading. In a scatter plot, users are viewing relative position, not size. A scatter plot omitting 0 is typically just using available space better, and users will compare their position and not their size more often.

**Question 2** (5 points). These points will be given for properly committing and pushing a .Rmd and a .html file with your exam answers.

nailed it.

**Question 3** (5 points). Tell me something you learned about ethics in data visualization.

Being aware of the consequences of your data visualizations. This could be recognizing when your data visualizations unfairly turn individual human lives into generalized data points, or when your data visualizations have an impact on current political rhetoric (such as swaying public opinions on criminal trials).

**Question 4** (20 points).

**part a.** A data set on United States election results was obtained from https://github.com/kjhealy/us_elections_2020_csv. Use the `maps` package, as well as this data set (posted on Sakai), to construct a map that fills each U.S. State with the percent of voters who voted for the republican candidate, Trump (`percent_gop`). For this problem,
- you do not need to worry about including Alaska or Hawaii. They are important but this is a timed exam!
- you should change the colour scale so that it is appropriate for the problem.

```{r}
library(maps)
library(tidyverse)
library(here)
election_df <- read_csv(here("data/2020_county_pres.csv")) %>%
  group_by(state_name) %>%
  summarise(total_gop = sum(votes_gop),
            total_dem = sum(votes_dem)) %>%
  mutate(percent_gop = 100 * total_gop / (total_gop + total_dem)) %>%
  mutate(state_name = str_to_lower(state_name))
```

```{r}
state_df <- ggplot2::map_data("state")

plot_df <- left_join(state_df, election_df, by = c("region" = "state_name"))

ggplot(data = plot_df,
            mapping = aes(x = long, y = lat,
                          group = group)) +
  geom_polygon(aes(fill = percent_gop), color = "black") +
  coord_map() + 
  theme_void() + 
  scale_fill_distiller(palette = "OrRd", direction = 1)
```

**part b.** Explain why the data frame R needs to construct a map of the United States is much, much longer than 50 rows.

because `geom_polygon` (used to graph the states), needs __each individual point__ (or at least each point of each line segmenet) of each state boundary to draw the map. Obviously, it takes more than 50 points to draw a map of the United States.

**Question 5** (25 points). Construct a `shiny` app using the `alcohol.csv` data set that has a scatterplot of the number of wine servings vs. the number of beer servings. In the app, the user should be able to select a country and have a label for that country appear on the app.

**In addition**, create an input that lets the user choose a variable (either `beer_servings`, `spirit_servings`, and `wine_servings`) and create an output that is a histogram based on that variable.

```{r}
library(shiny)
library(tidyverse)
library(ggrepel)
library(here)

alcohol_df <- read_csv(here("data/alcohol.csv"))
allcountries_df <- alcohol_df %>% group_by(country) %>% summarise()
vars_df <- alcohol_df %>% names %>% .[c(2, 3, 4)]

library(shiny)

ui <- fluidPage(
  selectInput(inputId = "countrychoice", label = "Select a Country",
              choices = allcountries_df),
  plotOutput("scatterplot"),
  selectInput(inputId = "varchoice", label = "Choose a variable",
              choices = vars_df),
  plotOutput("histplot")
)

server <- function(input, output, session) {
  
  onecountry_df <- reactive({ 
    alcohol_df %>% filter(country == input$countrychoice)
  })
  
  output$scatterplot <- renderPlot({

    ggplot(alcohol_df, aes(x = beer_servings, y = wine_servings)) +
      geom_point() +
      geom_label_repel(data = onecountry_df(), aes(label = country)) +
      geom_point(data = onecountry_df(), size = 3, shape = 1)
  })
  
  output$histplot <- renderPlot({
    ggplot(data = alcohol_df, aes_string(x = input$varchoice)) + 
      geom_histogram()
  })
  
}

shinyApp(ui, server)
```

**Question 6** (10 points). For the following `shiny app`, draw a reactive graph. I think the easiest way to do this would be to hand-draw the graph and hand it in on a piece of paper (there is paper at the front of the room). If you can figure out a way to draw it on your computer, you may do that and push that file to GitHub.

```{r, eval = FALSE}
ui <- fluidPage(
  radioButtons("input1"),
  selectInput("input2"),
  numericInput("input3"),
  plotOutput("output1"),
  tableOutput("output2")
)

server <- function(input, output, session) {
  
  df <- tibble(xvar = c(1, 2, 3), yvar = c("a", "b", "c"))
  
  newval <- reactive({
    input$input1 - input$input2
  })
  
  anotherval <- reactive({
    log(input$input1)
  })
  
  output$output1 <- renderPlot({
    plot(newval())
  })
  
  output$output2 <- renderTable({
    table(df[[input$input3]])
  })
}

shinyApp(ui, server)
```

**Question 7** (20 points). Consider again the women’s tennis data set, `wta_matches_2019.csv`, where each row corresponds to a match played on the WTA (Women’s Tennis Association) tour. Important variables to consider for this problem include:

- `winner_name`, the name of the player who won the match
- `loser_name`, the name of the player who lost the match

Construct a lollipop chart that shows the **10** WTA tennis players with the highest average number of aces in the 2019 season who have played **at least 20 matches**.

```{r}
library(tidyverse)
library(here)
wta_df <- read_csv(here("data/wta_matches_2019.csv"))
wta_long <- wta_df %>% pivot_longer(c(winner_name, loser_name),
                                    names_to = "won_or_lost",
                                    values_to = "player") %>%
  select(won_or_lost, player, w_ace, l_ace)

wta_new <- 
  wta_long %>%
  mutate(aces = if_else(won_or_lost == "winner_name", w_ace, l_ace)) %>%
  group_by(player)

wta_avg <-
  wta_new %>%
  filter(!is.na(aces)) %>%
  summarise(n_matches = n(), avg_aces = mean(aces))

wta_avg_filter <- 
  wta_avg %>%
  filter(n_matches >= 20) %>%
  slice_max(n = 10, avg_aces) %>%
  mutate(player = factor(player)) %>%
  ungroup() %>%
  mutate(player = fct_reorder(player, avg_aces))

ggplot(data = wta_avg_filter, aes(x = player, y = avg_aces)) +
  geom_segment(aes(xend = player, y = 0, yend = avg_aces)) +
  geom_point() +
  coord_flip()
```

**Question 8** (20 points).

**part a.** Consider the lollipop plot you made in **Question 7**. Why is this plot not the best plot to make to look at the top women’s servers in 2019? (There might be a couple of reasons but you should reference one that we have explicitly talked about in class a lot).

The lollipop chart is displaying a summary statistic, but is not doing a good job at showing that there is potential distribution and variability in the statistic. A viewer of this graph may conclude that Pliskova is __always__ a better server than Goerges, but surely we could find two games in which Goerges was a better server than Pliskova (and indeed we can).

**part b.** Fix the plot so that it no longer has the issue you described in **Question 8a**.

```{r}
wta_fixed <- 
  left_join(wta_new, wta_avg_filter, by = c("player" = "player")) %>%
  filter(!is.na(n_matches)) %>%
  filter(!is.na(aces)) %>%
  ungroup() %>%
  mutate(player = fct_reorder(factor(player), avg_aces))

ggplot(data = wta_fixed, aes(x = player, y = aces)) +
  geom_point(alpha = 0.5) +
  geom_point(aes(y = avg_aces), color = "red", size = 2) +
  coord_flip()
```

